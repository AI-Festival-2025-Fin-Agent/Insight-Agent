"""
DART í†µí•© ì‹œìŠ¤í…œ
íšŒì‚¬ëª…ìœ¼ë¡œ ê²€ìƒ‰ -> ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ -> ë¬¸ì„œ ë‚´ìš© -> JSON ì¶œë ¥
"""

import json
import requests
from datetime import datetime, timedelta
from dart_crawl import DartWebCrawler
from dart_doc_fetcher import DartDocumentFetcher


class DartIntegratedSystem:
    """DART ê²€ìƒ‰ê³¼ ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œì„ í†µí•©í•œ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.crawler = DartWebCrawler()

    def get_recent_and_fetch_documents(self, max_documents=5, mday_cnt=1, company_filter="", fetch_content=True, fetch_all=False):
        """
        ìµœê·¼ ê³µì‹œ ëª©ë¡ì„ ê°€ì ¸ì˜¤ê³  ë¬¸ì„œ ë‚´ìš©ê¹Œì§€ ì¶”ì¶œ

        Args:
            max_documents (int): ìµœëŒ€ ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜ (0=ì „ì²´, ê¸°ë³¸ 5ê°œ)
            mday_cnt (int): ê²€ìƒ‰ ê¸°ê°„ (1=ë‹¹ì¼, 2=2ì¼, 3=3ì¼, 7=7ì¼, 30=30ì¼)
            company_filter (str): íŠ¹ì • íšŒì‚¬ëª…ìœ¼ë¡œ í•„í„°ë§ (ì„ íƒì‚¬í•­, ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´)
            fetch_content (bool): ë¬¸ì„œ ë‚´ìš©ê¹Œì§€ ê°€ì ¸ì˜¬ì§€ ì—¬ë¶€ (ê¸°ë³¸ True)
            fetch_all (bool): ì „ì²´ í˜ì´ì§€ë¥¼ ë‹¤ ê°€ì ¸ì˜¬ì§€ ì—¬ë¶€ (ê¸°ë³¸ False)

        Returns:
            dict: JSON í˜•ì‹ì˜ ê²°ê³¼
        """
        print(f"ğŸ” ìµœê·¼ {mday_cnt}ì¼ê°„ ê³µì‹œ ê²€ìƒ‰ ë° ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ ì‹œì‘...")
        if company_filter:
            print(f"ğŸ¢ íšŒì‚¬ëª… í•„í„°: {company_filter}")
        if fetch_all:
            print(f"ğŸ“š ì „ì²´ ê³µì‹œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ (ëª¨ë“  í˜ì´ì§€)")

        result = {
            "search_type": "recent_disclosures",
            "search_date": datetime.now().isoformat(),
            "search_period_days": mday_cnt,
            "company_filter": company_filter,
            "fetch_all": fetch_all,
            "documents_found": 0,
            "documents_processed": 0,
            "documents": []
        }

        try:
            # 1. ìµœê·¼ ê³µì‹œ ê²€ìƒ‰
            print(f"ğŸ“‹ 1ë‹¨ê³„: ìµœê·¼ ê³µì‹œ ëª©ë¡ ê²€ìƒ‰...")
            disclosures = self.crawler.get_recent_disclosures(
                mday_cnt=mday_cnt,
                page=1,
                max_results=100,
                company_name=company_filter,
                fetch_all=fetch_all  # ì „ì²´ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì˜µì…˜
            )

            result["documents_found"] = len(disclosures)
            print(f"âœ… {len(disclosures)}ê±´ì˜ ê³µì‹œ ë°œê²¬")

            if not disclosures:
                print("âŒ ê²€ìƒ‰ëœ ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return result

            # 2. ìµœëŒ€ ê°œìˆ˜ë§Œí¼ ë¬¸ì„œ ì²˜ë¦¬
            if max_documents == 0:
                documents_to_process = disclosures  # ì „ì²´ ì²˜ë¦¬
            else:
                documents_to_process = disclosures[:max_documents]

            print(f"ğŸ“„ 2ë‹¨ê³„: {len(documents_to_process)}ê°œ ë¬¸ì„œ ì²˜ë¦¬...")

            if fetch_content:
                # requests ì‚¬ìš©í•œ ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ
                with DartDocumentFetcher() as fetcher:
                    for i, disclosure in enumerate(documents_to_process, 1):
                        print(f"\nğŸ“– {i}/{len(documents_to_process)}: {disclosure['report']}")

                        document_data = {
                            "index": i,
                            "basic_info": {
                                "company": disclosure['company'],
                                "report_name": disclosure['report'],
                                "submitter": disclosure['submitter'],
                                "date": disclosure['date'],
                                "rcept_no": disclosure['rcept_no'],
                                "url": disclosure['url'],
                                "is_correction": disclosure['is_correction']
                            },
                            "content": None,
                            "content_length": 0,
                            "extraction_status": "pending"
                        }

                        # ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ ì‹œë„
                        if disclosure['url']:
                            try:
                                doc_info = fetcher.get_document_content(disclosure['url'])
                                if doc_info and doc_info.get('content'):
                                    document_data["content"] = doc_info['content']
                                    document_data["content_length"] = len(doc_info['content'])
                                    document_data["extraction_status"] = "success"

                                    # ì¶”ê°€ ì •ë³´ê°€ ìˆë‹¤ë©´ í¬í•¨
                                    if doc_info.get('title'):
                                        document_data["basic_info"]["title"] = doc_info['title']

                                    print(f"âœ… ë‚´ìš© ì¶”ì¶œ ì™„ë£Œ ({document_data['content_length']} ë¬¸ì)")
                                else:
                                    document_data["extraction_status"] = "failed"
                                    print(f"âŒ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨")
                            except Exception as e:
                                document_data["extraction_status"] = "error"
                                document_data["error"] = str(e)
                                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        else:
                            document_data["extraction_status"] = "no_url"
                            print(f"âŒ URL ì—†ìŒ")

                        result["documents"].append(document_data)
                        result["documents_processed"] += 1

            else:
                # ë¬¸ì„œ ë‚´ìš© ì—†ì´ ê¸°ë³¸ ì •ë³´ë§Œ
                for i, disclosure in enumerate(documents_to_process, 1):
                    document_data = {
                        "index": i,
                        "basic_info": {
                            "company": disclosure['company'],
                            "report_name": disclosure['report'],
                            "submitter": disclosure['submitter'],
                            "date": disclosure['date'],
                            "rcept_no": disclosure['rcept_no'],
                            "url": disclosure['url'],
                            "is_correction": disclosure['is_correction']
                        },
                        "content": None,
                        "content_length": 0,
                        "extraction_status": "skipped"
                    }
                    result["documents"].append(document_data)
                    result["documents_processed"] += 1

            print(f"\nâœ… ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ: {result['documents_found']}ê±´")
            print(f"ğŸ“Š ì²˜ë¦¬ëœ ë¬¸ì„œ: {result['documents_processed']}ê±´")

            return result

        except Exception as e:
            result["error"] = str(e)
            print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            return result


    def save_results_to_json(self, result, filename=None):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            if result.get('search_type') == 'recent_disclosures':
                company_filter = result.get('company_filter', 'all')
                company_filter = company_filter.replace(' ', '_') if company_filter else 'all'
                filename = f"dart_recent_{company_filter}_{timestamp}.json"
            else:
                company_name = result.get('search_query', 'unknown').replace(' ', '_')
                filename = f"dart_results_{company_name}_{timestamp}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ê²°ê³¼ë¥¼ {filename}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            return filename
        except Exception as e:
            print(f"âŒ JSON ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def print_summary(self, result):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½")
        print("="*50)

        if result.get('search_type') == 'recent_disclosures':
            print(f"ğŸ” ê²€ìƒ‰ ìœ í˜•: ìµœê·¼ ê³µì‹œ")
            if result.get('company_filter'):
                print(f"ğŸ¢ íšŒì‚¬ í•„í„°: {result['company_filter']}")
            print(f"ğŸ“… ê²€ìƒ‰ ê¸°ê°„: ìµœê·¼ {result['search_period_days']}ì¼")
        else:
            print(f"ğŸ” ê²€ìƒ‰ì–´: {result.get('search_query', 'N/A')}")

        print(f"ğŸ“… ê²€ìƒ‰ì¼: {result['search_date'][:19]}")
        print(f"ğŸ“‹ ë°œê²¬ëœ ë¬¸ì„œ: {result['documents_found']}ê±´")
        print(f"ğŸ“„ ì²˜ë¦¬ëœ ë¬¸ì„œ: {result['documents_processed']}ê±´")

        if result.get('documents'):
            print(f"\nğŸ“ ë¬¸ì„œ ëª©ë¡:")
            for doc in result['documents']:
                print(f"  {doc['index']}. {doc['basic_info']['report_name']}")
                print(f"     ğŸ¢ {doc['basic_info']['company']}")
                print(f"     ğŸ“… {doc['basic_info']['date']} | ìƒíƒœ: {doc['extraction_status']}")
                if doc['content_length'] > 0:
                    print(f"     ğŸ“„ ë‚´ìš©: {doc['content_length']} ë¬¸ì")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    system = DartIntegratedSystem()

    print("ğŸ¯ DART í†µí•© ê²€ìƒ‰ ì‹œìŠ¤í…œ")
    print("="*40)

    while True:
        print("\nğŸ“‹ ì˜µì…˜ ì„ íƒ:")
        print("1. ìµœê·¼ ê³µì‹œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì‹ ê·œ)")
        print("2. ì¢…ë£Œ")

        choice = input("\nì„ íƒí•˜ì„¸ìš” (1-2): ").strip()

        if choice == '2':
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if choice != '1':
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
            continue

        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì…ë ¥
        print("\nğŸ“… ê²€ìƒ‰ ê¸°ê°„ ì„ íƒ:")
        print("1. ë‹¹ì¼")
        print("2. ìµœê·¼ 2ì¼")
        print("3. ìµœê·¼ 3ì¼")
        print("7. ìµœê·¼ 7ì¼")
        print("30. ìµœê·¼ 30ì¼")

        mday_input = input("\nê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš” (ê¸°ë³¸ê°’: 1): ").strip()
        mday_cnt = int(mday_input) if mday_input.isdigit() and int(mday_input) in [1, 2, 3, 7, 30] else 1

        # íšŒì‚¬ëª… í•„í„°ë§ (ì„ íƒì‚¬í•­)
        company_filter = input("\nğŸ¢ íŠ¹ì • íšŒì‚¬ëª…ìœ¼ë¡œ í•„í„°ë§í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ì—”í„°=ì „ì²´): ").strip()

        # ì „ì²´ ê³µì‹œ ê°€ì ¸ì˜¤ê¸° ì—¬ë¶€
        fetch_all_choice = input("\nğŸ“š í•´ë‹¹ ê¸°ê°„ì˜ ê³µì‹œë¥¼ ì „ë¶€ ê°€ì ¸ì˜¤ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        fetch_all = (fetch_all_choice == 'y')

        if fetch_all:
            print("âœ… ì „ì²´ ê³µì‹œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ (ë¬¸ì„œ ë‚´ìš©ì€ ê°€ì ¸ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤)")
            max_docs = 0  # ì „ì²´ ê°€ì ¸ì˜¤ê¸°
            fetch_content = False  # ì „ì²´ ê°€ì ¸ì˜¬ ë•ŒëŠ” ë‚´ìš©ì€ ìŠ¤í‚µ
        else:
            max_docs_input = input("ğŸ“„ ìµœëŒ€ ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ê°’: 5): ").strip()
            max_docs = int(max_docs_input) if max_docs_input.isdigit() else 5
            fetch_content = True

        # ê²€ìƒ‰ ì‹¤í–‰
        try:
            print("\nğŸš€ ê²€ìƒ‰ ì‹œì‘...")
            result = system.get_recent_and_fetch_documents(
                max_documents=max_docs,
                mday_cnt=mday_cnt,
                company_filter=company_filter,
                fetch_content=fetch_content,
                fetch_all=fetch_all
            )

            # ê²°ê³¼ ì¶œë ¥
            system.print_summary(result)

            # JSON ì €ì¥ ì—¬ë¶€ í™•ì¸
            save_choice = input(f"\nğŸ’¾ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
            if save_choice == 'y':
                filename = system.save_results_to_json(result)
                if filename:
                    print(f"âœ… {filename}ì— ì €ì¥ ì™„ë£Œ")

            # JSON ì¶œë ¥ ì—¬ë¶€ í™•ì¸
            json_choice = input(f"\nğŸ“‹ JSON ê²°ê³¼ë¥¼ í™”ë©´ì— ì¶œë ¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
            if json_choice == 'y':
                print(f"\nğŸ“‹ JSON ê²°ê³¼:")
                print("="*50)
                print(json.dumps(result, ensure_ascii=False, indent=2))

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()